# ğŸš€ MMP Local Dev Environment

> **Modern ML Pipeline (MMP) ë¡œì»¬ ê°œë°œ í™˜ê²½**  
> PostgreSQL + Redis + MLflow + Feast Feature Store ì™„ì „ í†µí•© ê°œë°œ ìŠ¤íƒ

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-required-blue.svg)](https://www.docker.com/)

---

## ğŸ“– **ê°œìš”**

**mmp-local-dev**ëŠ” [modern-ml-pipeline](../modern-ml-pipeline/) í”„ë¡œì íŠ¸ì˜ **ì™„ì „í•œ ê°œë°œ í™˜ê²½ ë°±ë³¸**ì…ë‹ˆë‹¤.  
MLflow Graceful Degradation íŒ¨í„´ì„ êµ¬í˜„í•˜ì—¬, modern-ml-pipelineì´ 3ê°€ì§€ ëª¨ë“œì—ì„œ ë™ì‘í•  ìˆ˜ ìˆê²Œ ì§€ì›í•©ë‹ˆë‹¤:

- **ğŸ”¥ Full Stack Mode**: mmp-local-devì˜ ëª¨ë“  ì¸í”„ë¼ ì„œë¹„ìŠ¤ í™œìš©
- **ğŸ“ Local File Mode**: MLflow íŒŒì¼ ì €ì¥, ë¡œì»¬ Feature Store  
- **â˜ï¸ Production Mode**: í´ë¼ìš°ë“œ MLflow, í”„ë¡œë•ì…˜ Feature Store

### **ğŸ¯ í•µì‹¬ ê°€ì¹˜**
- **Zero Setup**: 5ë¶„ ë‚´ ì™„ì „í•œ ML ê°œë°œ í™˜ê²½ êµ¬ì¶•
- **Full Stack**: ë°ì´í„° â†’ Feature Store â†’ ML Pipeline â†’ Serving ì „ì²´ íë¦„
- **Test Ready**: modern-ml-pipelineì˜ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì§€ì›
- **Contract-Based**: dev-contract.yml ê¸°ë°˜ ì—„ê²©í•œ API ê³„ì•½

---

## ğŸ—ï¸ **ì•„í‚¤í…ì²˜**

```mermaid
graph TB
    subgraph "mmp-local-dev Infrastructure"
        PG[(PostgreSQL<br/>Port: 5432)]
        RD[(Redis<br/>Port: 6379)]
        ML[MLflow Server<br/>Port: 5002]
        FS[Feast Feature Store<br/>Registry + Config]
    end
    
    subgraph "modern-ml-pipeline"
        TR[Training Pipeline]
        PR[Prediction Pipeline]
        SV[Serving API]
    end
    
    subgraph "Data Flow"
        PG --> FS
        FS --> RD
        FS --> TR
        TR --> ML
        ML --> PR
        RD --> SV
    end
    
    subgraph "Test Data"
        TD[ML Test Dataset<br/>1000+ samples]
        SC[Scenario Cases<br/>Success/Partial/Fail]
    end
    
    TD --> PG
    SC --> FS
```

### **ì„œë¹„ìŠ¤ êµ¬ì„±**

| ì„œë¹„ìŠ¤ | í¬íŠ¸ | ì—­í•  | ë°ì´í„° ì €ì¥ |
|-------|------|------|-----------|
| **PostgreSQL** | 5432 | Feast Offline Store | `/var/lib/postgresql/data` |
| **Redis** | 6379 | Feast Online Store | `/data` |
| **MLflow** | 5002 | ì‹¤í—˜ ì¶”ì  & ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ | `./mlflow-artifacts/` |
| **Feast** | - | Feature Store ë ˆì§€ìŠ¤íŠ¸ë¦¬ | `./feast/data/` |

---

## âš¡ **ë¹ ë¥¸ ì‹œì‘**

### **1. ì‚¬ì „ ì¤€ë¹„**
```bash
# Docker í™˜ê²½ í™•ì¸ (Docker Desktop ë˜ëŠ” OrbStack)
docker --version
docker-compose --version

# í”„ë¡œì íŠ¸ í´ë¡ 
git clone <repository-url>
cd mmp-local-dev
```

### **2. í™˜ê²½ ì„¤ì • & ì‹¤í–‰**
```bash
# í•œ ë²ˆì— ëª¨ë“  í™˜ê²½ êµ¬ì¶•
./setup.sh

# ğŸ‰ ì™„ë£Œ! ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ìë™ìœ¼ë¡œ ì‹œì‘ë©ë‹ˆë‹¤
```

### **3. ì—°ê²° í…ŒìŠ¤íŠ¸**
```bash
# í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python test-integration.py

# ê°œë³„ ì„œë¹„ìŠ¤ í™•ì¸
./setup.sh --status
```

### **4. Modern ML Pipeline ì‹¤í–‰**
```bash
# MMP ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd ../modern-ml-pipeline

# DEV í™˜ê²½ì—ì„œ í•™ìŠµ ì‹¤í–‰
APP_ENV=dev uv run python main.py train --recipe-file dev_classification_test

# API ì„œë¹™ ì‹œì‘
APP_ENV=dev uv run python main.py serve-api --run-id latest
```

---

## ğŸ—„ï¸ **ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ**

### **Feature Store ìŠ¤í‚¤ë§ˆ (features)**

mmp-local-devëŠ” **4ê°œ í•µì‹¬ í”¼ì²˜ í…Œì´ë¸”**ì„ ì œê³µí•©ë‹ˆë‹¤:

#### **1. user_demographics** - ì‚¬ìš©ì ê¸°ë³¸ ì •ë³´
```sql
CREATE TABLE features.user_demographics (
    user_id VARCHAR(50) PRIMARY KEY,        -- Entity: ì‚¬ìš©ì ì‹ë³„ì
    age INTEGER,                            -- ì—°ë ¹
    country_code VARCHAR(2),                -- êµ­ê°€ ì½”ë“œ (ISO 2ìë¦¬)
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### **2. user_purchase_summary** - êµ¬ë§¤ ìš”ì•½
```sql
CREATE TABLE features.user_purchase_summary (
    user_id VARCHAR(50) PRIMARY KEY,
    ltv DECIMAL(10,2),                      -- Life Time Value
    total_purchase_count INTEGER,           -- ì´ êµ¬ë§¤ íšŸìˆ˜
    last_purchase_date DATE,                -- ë§ˆì§€ë§‰ êµ¬ë§¤ì¼
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### **3. product_details** - ìƒí’ˆ ì •ë³´
```sql
CREATE TABLE features.product_details (
    product_id VARCHAR(50) PRIMARY KEY,     -- Entity: ìƒí’ˆ ì‹ë³„ì
    price DECIMAL(10,2),                    -- ê°€ê²©
    category VARCHAR(100),                  -- ì¹´í…Œê³ ë¦¬
    brand VARCHAR(100),                     -- ë¸Œëœë“œ
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### **4. session_summary** - ì„¸ì…˜ ìš”ì•½
```sql
CREATE TABLE features.session_summary (
    session_id VARCHAR(50) PRIMARY KEY,     -- Entity: ì„¸ì…˜ ì‹ë³„ì
    time_on_page_seconds INTEGER,           -- í˜ì´ì§€ ì²´ë¥˜ ì‹œê°„
    click_count INTEGER,                    -- í´ë¦­ ìˆ˜
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### **í˜„ì¬ ë°ì´í„° í˜„í™©**
- **user_demographics**: 100ê°œ ì‚¬ìš©ì (user_001 ~ user_100)
- **user_purchase_summary**: 100ê°œ êµ¬ë§¤ ìš”ì•½
- **product_details**: 50ê°œ ìƒí’ˆ (prod_001 ~ prod_050)  
- **session_summary**: 200ê°œ ì„¸ì…˜ (sess_001 ~ sess_200)

---

## ğŸ§ª **ML í…ŒìŠ¤íŠ¸ ë°ì´í„° í†µí•©**

### **modern-ml-pipeline í˜¸í™˜ì„±**

mmp-local-devëŠ” modern-ml-pipelineì˜ **ëª¨ë“  Recipeì™€ 100% í˜¸í™˜**ë˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

#### **í•µì‹¬ í˜¸í™˜ í…Œì´ë¸”: `ml_test_dataset`**

modern-ml-pipelineì˜ `local_classification_test` Recipeì™€ ì™„ë²½ í˜¸í™˜:

```sql
CREATE TABLE features.ml_test_dataset (
    -- Entity ìŠ¤í‚¤ë§ˆ (Recipe í•„ìˆ˜)
    user_id VARCHAR(50),                    -- ì‚¬ìš©ì ì‹ë³„ì
    event_timestamp TIMESTAMP,              -- ì´ë²¤íŠ¸ íƒ€ì„ìŠ¤íƒ¬í”„
    
    -- ML Features (Recipe ì •ì˜)
    age INTEGER,                            -- ì—°ë ¹
    income DECIMAL(10,2),                   -- ì†Œë“
    credit_score INTEGER,                   -- ì‹ ìš© ì ìˆ˜  
    region VARCHAR(20),                     -- ì§€ì—­ (North/South/East/West)
    occupation VARCHAR(50),                 -- ì§ì—… (Engineer/Teacher/Doctor/Other)
    
    -- Target Variable
    approved INTEGER,                       -- ìŠ¹ì¸ ì—¬ë¶€ (0/1)
    
    -- Meta
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### **ë°ì´í„° ì¶”ê°€ ê°€ì´ë“œ**

#### **Step 1: ê¸°ë³¸ ML í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±**

```bash
# 1. ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > scripts/seed-ml-test-data.sql << 'EOF'
-- Modern ML Pipeline í˜¸í™˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°
SET search_path TO features, public;

-- ML í…ŒìŠ¤íŠ¸ ë°ì´í„° í…Œì´ë¸” ìƒì„±
CREATE TABLE IF NOT EXISTS ml_test_dataset (
    user_id VARCHAR(50),
    event_timestamp TIMESTAMP,
    age INTEGER,
    income DECIMAL(10,2),
    credit_score INTEGER,
    region VARCHAR(20),
    occupation VARCHAR(50),
    approved INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ê¸°ì¡´ Feature Store ì‚¬ìš©ìì™€ êµì§‘í•© ë³´ì¥í•˜ëŠ” 1000ê°œ ìƒ˜í”Œ ìƒì„±
INSERT INTO ml_test_dataset (user_id, event_timestamp, age, income, credit_score, region, occupation, approved)
SELECT 
    CASE 
        WHEN ROW_NUMBER() OVER() <= 100 THEN 'user_' || LPAD(ROW_NUMBER() OVER()::text, 3, '0')  -- ê¸°ì¡´ ì‚¬ìš©ì í™œìš©
        ELSE 'test_user_' || (ROW_NUMBER() OVER() - 100)  -- ìƒˆ í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì
    END as user_id,
    CURRENT_TIMESTAMP + (ROW_NUMBER() OVER() * INTERVAL '1 hour') as event_timestamp,
    (RANDOM() * 30 + 25)::INTEGER as age,  -- 25-55ì„¸
    (EXP(RANDOM() * 2 + 9))::DECIMAL(10,2) as income,  -- ë¡œê·¸ì •ê·œë¶„í¬ ì†Œë“
    (RANDOM() * 550 + 300)::INTEGER as credit_score,  -- 300-850 ì‹ ìš©ì ìˆ˜
    CASE (RANDOM() * 4)::INTEGER 
        WHEN 0 THEN 'North'
        WHEN 1 THEN 'South' 
        WHEN 2 THEN 'East'
        ELSE 'West'
    END as region,
    CASE (RANDOM() * 4)::INTEGER
        WHEN 0 THEN 'Engineer'
        WHEN 1 THEN 'Teacher'
        WHEN 2 THEN 'Doctor' 
        ELSE 'Other'
    END as occupation,
    CASE WHEN RANDOM() < 0.35 THEN 1 ELSE 0 END as approved  -- 35% ìŠ¹ì¸ìœ¨
FROM generate_series(1, 1000);

-- ì¸ë±ìŠ¤ ìƒì„± (ì„±ëŠ¥ ìµœì í™”)
CREATE INDEX IF NOT EXISTS idx_ml_test_dataset_user_id ON ml_test_dataset(user_id);
CREATE INDEX IF NOT EXISTS idx_ml_test_dataset_event_timestamp ON ml_test_dataset(event_timestamp);

ANALYZE ml_test_dataset;
EOF

# 2. ë°ì´í„° íˆ¬ì…
docker-compose exec -T postgresql psql -U mluser -d mlpipeline < scripts/seed-ml-test-data.sql
```

#### **Step 2: ì‹œë‚˜ë¦¬ì˜¤ë³„ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±**

```bash
# í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ í…Œì´ë¸” ìƒì„±
cat > scripts/seed-test-scenarios.sql << 'EOF'
SET search_path TO features, public;

-- ì‹œë‚˜ë¦¬ì˜¤ë³„ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ í…Œì´ë¸”
CREATE TABLE IF NOT EXISTS feature_lookup_test (
    test_id SERIAL PRIMARY KEY,
    user_id VARCHAR(50),
    request_timestamp TIMESTAMP,
    test_scenario VARCHAR(50),              -- 'success', 'partial_fail', 'complete_fail'
    expected_features JSONB,                -- ì˜ˆìƒ Feature Store ì‘ë‹µ
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ì„±ê³µ ì¼€ì´ìŠ¤ (200ê°œ): ëª¨ë“  í”¼ì²˜ ì™„ì „ ë³´ìœ 
INSERT INTO feature_lookup_test (user_id, request_timestamp, test_scenario, expected_features)
SELECT 
    'user_' || LPAD((ROW_NUMBER() OVER() % 100 + 1)::text, 3, '0'),
    CURRENT_TIMESTAMP,
    'success',
    jsonb_build_object(
        'age', ud.age,
        'country_code', ud.country_code,
        'ltv', ups.ltv,
        'total_purchase_count', ups.total_purchase_count
    )
FROM generate_series(1, 200), 
     features.user_demographics ud,
     features.user_purchase_summary ups
WHERE ud.user_id = ups.user_id
  AND ud.user_id = 'user_' || LPAD((ROW_NUMBER() OVER() % 100 + 1)::text, 3, '0')
LIMIT 200;

-- ë¶€ë¶„ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ (100ê°œ): ì¼ë¶€ í”¼ì²˜ ëˆ„ë½
INSERT INTO feature_lookup_test (user_id, request_timestamp, test_scenario, expected_features)
SELECT 
    'partial_user_' || generate_series,
    CURRENT_TIMESTAMP,
    'partial_fail', 
    jsonb_build_object('age', (RANDOM() * 30 + 25)::INTEGER)  -- ageë§Œ ì¡´ì¬
FROM generate_series(1, 100);

-- ì™„ì „ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ (50ê°œ): Feature Store ì—°ê²° ë¶ˆê°€
INSERT INTO feature_lookup_test (user_id, request_timestamp, test_scenario, expected_features)
SELECT 
    'fail_user_' || generate_series,
    CURRENT_TIMESTAMP,
    'complete_fail',
    '{}'::jsonb  -- ë¹ˆ ì‘ë‹µ
FROM generate_series(1, 50);
EOF

# ì‹¤í–‰
docker-compose exec -T postgresql psql -U mluser -d mlpipeline < scripts/seed-test-scenarios.sql
```

#### **Step 3: Feature Store Materialization**

```python
# scripts/materialize-features.py
#!/usr/bin/env python3
"""Feature Store ë°ì´í„°ë¥¼ Redis Online Storeë¡œ Materialize"""

import os
import sys
from datetime import datetime, timedelta
import pandas as pd

# Feast ë””ë ‰í† ë¦¬ë¡œ ì´ë™
os.chdir('./feast')

try:
    from feast import FeatureStore
    
    # Feature Store ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    fs = FeatureStore(repo_path=".")
    
    print("ğŸ”„ Feature Store Materialization ì‹œì‘...")
    
    # ì „ì²´ í”¼ì²˜ ë·°ì— ëŒ€í•´ materialization ìˆ˜í–‰
    feature_views = fs.list_feature_views()
    
    for fv in feature_views:
        print(f"ğŸ“Š {fv.name} materialization ì¤‘...")
        
        # ì§€ë‚œ 30ì¼ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ materialize
        start_date = datetime.now() - timedelta(days=30)
        end_date = datetime.now()
        
        fs.materialize_incremental(
            feature_views=[fv],
            end_date=end_date
        )
        
        print(f"âœ… {fv.name} materialization ì™„ë£Œ")
    
    print("ğŸ‰ ì „ì²´ Feature Store Materialization ì™„ë£Œ!")
    
    # í…ŒìŠ¤íŠ¸: ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ
    print("\nğŸ“‹ í…ŒìŠ¤íŠ¸: ìƒ˜í”Œ í”¼ì²˜ ì¡°íšŒ")
    entity_df = pd.DataFrame({
        "user_id": ["user_001", "user_002", "user_003"],
        "event_timestamp": [datetime.now()] * 3
    })
    
    online_features = fs.get_online_features(
        features=[
            "user_demographics:age",
            "user_demographics:country_code", 
            "user_purchase_summary:ltv"
        ],
        entity_rows=[
            {"user_id": "user_001"},
            {"user_id": "user_002"}, 
            {"user_id": "user_003"}
        ]
    )
    
    print("âœ… Online Feature ì¡°íšŒ ì„±ê³µ:")
    print(online_features.to_dict())
    
except Exception as e:
    print(f"âŒ Materialization ì‹¤íŒ¨: {str(e)}")
    sys.exit(1)
```

```bash
# Materialization ì‹¤í–‰
python scripts/materialize-features.py
```

### **ë°ì´í„° ê²€ì¦**

```bash
# 1. ë°ì´í„° ê±´ìˆ˜ í™•ì¸
docker-compose exec -T postgresql psql -U mluser -d mlpipeline -c "
SELECT 
    'user_demographics' as table_name, COUNT(*) as row_count 
FROM features.user_demographics
UNION ALL
SELECT 
    'ml_test_dataset', COUNT(*) 
FROM features.ml_test_dataset
UNION ALL  
SELECT 
    'feature_lookup_test', COUNT(*)
FROM features.feature_lookup_test;
"

# 2. Feature Store ì—°ê²° í…ŒìŠ¤íŠ¸
cd feast && feast validate

# 3. Redis ë°ì´í„° í™•ì¸
docker-compose exec redis redis-cli --scan --pattern "*user_demographics*" | head -10
```

---

## ğŸ§ª **í…ŒìŠ¤íŠ¸ ì‹¤í–‰**

### **í†µí•© í…ŒìŠ¤íŠ¸**
```bash
# ì „ì²´ ìŠ¤íƒ ê²€ì¦
python test-integration.py

# ì˜ˆìƒ ì¶œë ¥:
# âœ… PASS ê³„ì•½ ì¤€ìˆ˜ (Contract Compliance)
# âœ… PASS PostgreSQL ì—°ê²°  
# âœ… PASS Redis ì—°ê²°
# âœ… PASS MLflow ì„œë²„
# âœ… PASS Feast í”¼ì²˜
# ğŸ‰ ì´ 5ê°œ í…ŒìŠ¤íŠ¸ ì¤‘ 5ê°œ í†µê³¼ (100.0%)
```

### **Modern ML Pipeline í…ŒìŠ¤íŠ¸**
```bash
cd ../modern-ml-pipeline

# 1. Unit í…ŒìŠ¤íŠ¸ (ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥)
uv run pytest tests/unit/ -v

# 2. Integration í…ŒìŠ¤íŠ¸ (DEV ìŠ¤íƒ í•„ìš”)
APP_ENV=dev uv run pytest tests/integration/ -v

# 3. E2E í…ŒìŠ¤íŠ¸ (ì „ì²´ ì›Œí¬í”Œë¡œìš°)
APP_ENV=dev uv run pytest tests/e2e/ -v

# 4. Feature Store ì •í•©ì„± í…ŒìŠ¤íŠ¸
uv run pytest tests/integration/test_feature_store_parity.py -v
uv run pytest tests/integration/test_feature_store_point_in_time.py -v
```

### **Serving API í…ŒìŠ¤íŠ¸**
```bash
# API ì„œë²„ ì‹œì‘
APP_ENV=dev uv run python main.py serve-api --run-id latest &

# API í…ŒìŠ¤íŠ¸
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "user_001",
    "age": 35,
    "income": 75000,
    "credit_score": 720,
    "region": "North",
    "occupation": "Engineer"
  }'

# ì˜ˆìƒ ì‘ë‹µ (DEV í™˜ê²½):
# {"prediction": 1, "probability": 0.73, "status": "success"}

# ì˜ˆìƒ ì‘ë‹µ (Local í™˜ê²½):  
# {"error": "Feature Store unavailable", "status_code": 503}
```

---

## ğŸ“Š **Feature Store í™œìš©**

### **Feast í”¼ì²˜ ì¡°íšŒ**

#### **Historical Features (Offline Store)**
```python
from feast import FeatureStore
import pandas as pd
from datetime import datetime

# Feature Store ì´ˆê¸°í™”  
fs = FeatureStore(repo_path="./feast")

# ì—”í‹°í‹° DataFrame ì¤€ë¹„
entity_df = pd.DataFrame({
    "user_id": ["user_001", "user_002", "user_003"],
    "event_timestamp": [datetime.now()] * 3
})

# Historical features ì¡°íšŒ (í•™ìŠµìš©)
training_df = fs.get_historical_features(
    entity_df=entity_df,
    features=[
        "user_demographics:age",
        "user_demographics:country_code",
        "user_purchase_summary:ltv",
        "user_purchase_summary:total_purchase_count"
    ]
).to_df()

print("ğŸ“Š Historical Features:")
print(training_df.head())
```

#### **Online Features (Redis)**
```python
# Online features ì¡°íšŒ (ì‹¤ì‹œê°„ ì˜ˆì¸¡ìš©)
online_features = fs.get_online_features(
    features=[
        "user_demographics:age",
        "user_purchase_summary:ltv"
    ],
    entity_rows=[
        {"user_id": "user_001"},
        {"user_id": "user_002"}
    ]
)

print("âš¡ Online Features:")
print(online_features.to_dict())
```

### **ì»¤ìŠ¤í…€ í”¼ì²˜ ì¶”ê°€**

ìƒˆë¡œìš´ í”¼ì²˜ë¥¼ ì¶”ê°€í•˜ë ¤ë©´:

#### **1. PostgreSQLì— í…Œì´ë¸” ìƒì„±**
```sql
-- ìƒˆë¡œìš´ í”¼ì²˜ í…Œì´ë¸” ì˜ˆì‹œ
CREATE TABLE features.user_engagement (
    user_id VARCHAR(50) PRIMARY KEY,
    page_views INTEGER,
    session_duration_avg DECIMAL(8,2),
    bounce_rate DECIMAL(5,4),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ìƒ˜í”Œ ë°ì´í„° ì‚½ì…
INSERT INTO features.user_engagement (user_id, page_views, session_duration_avg, bounce_rate)
SELECT 
    user_id,
    (RANDOM() * 100 + 10)::INTEGER,  -- 10-110 í˜ì´ì§€ë·°
    (RANDOM() * 300 + 60)::DECIMAL(8,2),  -- 60-360ì´ˆ ì„¸ì…˜
    (RANDOM() * 0.5 + 0.1)::DECIMAL(5,4)  -- 10-60% ë°”ìš´ìŠ¤ìœ¨
FROM features.user_demographics;
```

#### **2. Feast FeatureView ì •ì˜**
```python
# feast/features.pyì— ì¶”ê°€
user_engagement_source = PostgreSQLSource(
    name="user_engagement_source",
    query="SELECT user_id, page_views, session_duration_avg, bounce_rate, created_at FROM features.user_engagement",
    timestamp_field="created_at"
)

user_engagement_fv = FeatureView(
    name="user_engagement",
    entities=[user],  # ê¸°ì¡´ user entity ì¬ì‚¬ìš©
    ttl=timedelta(days=7),
    schema=[
        Field(name="page_views", dtype=Int64),
        Field(name="session_duration_avg", dtype=Float32),
        Field(name="bounce_rate", dtype=Float32),
    ],
    source=user_engagement_source
)
```

#### **3. Feature Store ì—…ë°ì´íŠ¸**
```bash
cd feast
feast apply  # ìƒˆ FeatureView ë“±ë¡
feast materialize-incremental $(date -d '1 day ago' +%Y-%m-%d) $(date +%Y-%m-%d)  # Materialize
```

---

## ğŸ› ï¸ **í™˜ê²½ ê´€ë¦¬**

### **ì„œë¹„ìŠ¤ ì œì–´**
```bash
# ì „ì²´ í™˜ê²½ ì¬ì‹œì‘
./setup.sh

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
./setup.sh --status
docker-compose ps

# ì„œë¹„ìŠ¤ ì¤‘ì§€
./setup.sh --stop
# ë˜ëŠ”
docker-compose down

# ë°ì´í„° í¬í•¨ ì™„ì „ ì‚­ì œ
./setup.sh --clean
# ë˜ëŠ”  
docker-compose down -v
```

### **ê°œë³„ ì„œë¹„ìŠ¤ ë””ë²„ê¹…**
```bash
# PostgreSQL ì§ì ‘ ì ‘ì†
docker-compose exec postgresql psql -U mluser -d mlpipeline

# Redis ì§ì ‘ ì ‘ì†
docker-compose exec redis redis-cli

# MLflow ë¡œê·¸ í™•ì¸
docker-compose logs mlflow

# Feast ì„¤ì • í™•ì¸
cd feast && feast validate
```

### **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**
```bash
# ì„œë¹„ìŠ¤ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
docker-compose ps --format "table {{.Name}}\t{{.Status}}\t{{.Size}}"

# PostgreSQL ì—°ê²° ìˆ˜
docker-compose exec postgresql psql -U mluser -d mlpipeline -c "
SELECT count(*) as active_connections 
FROM pg_stat_activity 
WHERE state = 'active';"

# Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
docker-compose exec redis redis-cli info memory | grep used_memory_human

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
du -sh mlflow-artifacts/ feast/data/ 
```

---

## ğŸ”§ **ê³ ê¸‰ ì„¤ì •**

### **í™˜ê²½ë³€ìˆ˜ ì»¤ìŠ¤í„°ë§ˆì´ì§•**

`.env` íŒŒì¼ì„ ìˆ˜ì •í•˜ì—¬ ì„¤ì • ë³€ê²½:

```bash
# .env íŒŒì¼ ì˜ˆì‹œ
POSTGRES_HOST=localhost
POSTGRES_PORT=5432  
POSTGRES_USER=mluser
POSTGRES_DB=mlpipeline
POSTGRES_PASSWORD=secure_password_123

REDIS_HOST=localhost
REDIS_PORT=6379

# MLflow ì„¤ì • - modern-ml-pipelineê³¼ í¬íŠ¸ í†µì¼ 
MLFLOW_TRACKING_URI=http://localhost:5002

# ì¶”ê°€ ì„¤ì •
COMPOSE_PROJECT_NAME=mmp-local-dev
MLFLOW_ARTIFACT_ROOT=./mlflow-artifacts
```

### **Production ë°°í¬ ì¤€ë¹„**

```bash
# Production í™˜ê²½ë³€ìˆ˜ í…œí”Œë¦¿
cat > .env.production << 'EOF'
# Production PostgreSQL (ì™¸ë¶€ ì„œë²„)
POSTGRES_HOST=prod-postgres.example.com
POSTGRES_PORT=5432
POSTGRES_USER=mlpipeline_prod
POSTGRES_DB=mlpipeline_prod
POSTGRES_PASSWORD=${POSTGRES_PROD_PASSWORD}

# Production Redis (ì™¸ë¶€ ì„œë²„) 
REDIS_HOST=prod-redis.example.com
REDIS_PORT=6379
REDIS_PASSWORD=${REDIS_PROD_PASSWORD}

# Production MLflow (ì™¸ë¶€ ì„œë²„)
MLFLOW_TRACKING_URI=https://mlflow.example.com

# S3 ì•„í‹°íŒ©íŠ¸ ìŠ¤í† ì–´
MLFLOW_S3_ENDPOINT_URL=https://s3.amazonaws.com
AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
EOF
```

### **ë°±ì—… ë° ë³µì›**

```bash
# PostgreSQL ë°±ì—…
docker-compose exec postgresql pg_dump -U mluser -d mlpipeline > backup_$(date +%Y%m%d).sql

# PostgreSQL ë³µì›  
docker-compose exec -T postgresql psql -U mluser -d mlpipeline < backup_20240119.sql

# Redis ë°±ì—…
docker-compose exec redis redis-cli --rdb dump.rdb
docker cp $(docker-compose ps -q redis):/data/dump.rdb ./redis_backup_$(date +%Y%m%d).rdb

# ì „ì²´ ë°ì´í„° ë””ë ‰í† ë¦¬ ë°±ì—…
tar -czf mmp_local_dev_backup_$(date +%Y%m%d).tar.gz \
  mlflow-artifacts/ \
  feast/data/ \
  postgres_data/ \
  redis_data/
```

---

## ğŸš¨ **íŠ¸ëŸ¬ë¸”ìŠˆíŒ…**

### **ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ**

#### **1. í¬íŠ¸ ì¶©ëŒ**
```bash
# í¬íŠ¸ ì‚¬ìš© ì¤‘ í™•ì¸
lsof -i :5432  # PostgreSQL
lsof -i :6379  # Redis  
lsof -i :5002  # MLflow

# í•´ê²°ë°©ë²•: ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ í›„ ì¬ì‹œì‘
./setup.sh --clean && ./setup.sh
```

#### **2. PostgreSQL ì—°ê²° ì‹¤íŒ¨**
```bash
# ë¡œê·¸ í™•ì¸
docker-compose logs postgresql

# ì—°ê²° í…ŒìŠ¤íŠ¸
docker-compose exec postgresql psql -U mluser -d mlpipeline -c "SELECT 1;"

# ì¼ë°˜ì  í•´ê²°ë°©ë²•
docker-compose restart postgresql
```

#### **3. Feast ì„¤ì • ì˜¤ë¥˜**
```bash
# Feast ì„¤ì • ê²€ì¦
cd feast && feast validate

# ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¬ìƒì„±
rm -rf data/registry.db
feast apply

# Materialization ì¬ì‹¤í–‰
feast materialize-incremental $(date -d '7 days ago' +%Y-%m-%d) $(date +%Y-%m-%d)
```

#### **4. MLflow ì„œë²„ ì ‘ì† ë¶ˆê°€**
```bash
# MLflow ì„œë²„ ë¡œê·¸ í™•ì¸
docker-compose logs mlflow

# ìˆ˜ë™ ì¬ì‹œì‘
docker-compose restart mlflow

# ë¸Œë¼ìš°ì €ì—ì„œ í™•ì¸
open http://localhost:5002
```

### **ì„±ëŠ¥ ë¬¸ì œ**

#### **PostgreSQL ì¿¼ë¦¬ ìµœì í™”**
```sql
-- ëŠë¦° ì¿¼ë¦¬ ì‹ë³„
SELECT query, mean_time, calls 
FROM pg_stat_statements 
ORDER BY mean_time DESC 
LIMIT 10;

-- ì¸ë±ìŠ¤ ì‚¬ìš©ë¥  í™•ì¸
SELECT schemaname, tablename, indexname, idx_tup_read, idx_tup_fetch 
FROM pg_stat_user_indexes 
ORDER BY idx_tup_read DESC;
```

#### **Redis ë©”ëª¨ë¦¬ ìµœì í™”**
```bash
# Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
docker-compose exec redis redis-cli --bigkeys

# ë©”ëª¨ë¦¬ ì •ì±… í™•ì¸
docker-compose exec redis redis-cli config get maxmemory-policy
```

---

## ğŸ¤ **modern-ml-pipeline í†µí•© ê°€ì´ë“œ**

### **ê°œë°œ ì›Œí¬í”Œë¡œìš°**

#### **1. ìƒˆ ML ì‹¤í—˜ ì‹œì‘**
```bash
# 1. mmp-local-dev í™˜ê²½ ì‹œì‘
cd mmp-local-dev
./setup.sh

# 2. ë°ì´í„° í™•ì¸ ë° Feature Store í…ŒìŠ¤íŠ¸
python test-integration.py

# 3. modern-ml-pipelineì—ì„œ ì‹¤í—˜
cd ../modern-ml-pipeline
APP_ENV=dev uv run python main.py train --recipe-file your_recipe

# 4. ê²°ê³¼ í™•ì¸
open http://localhost:5002  # MLflow UI
```

#### **2. API ì„œë¹™ í…ŒìŠ¤íŠ¸**
```bash
# 1. ëª¨ë¸ í•™ìŠµ (ìœ„ ë‹¨ê³„ ì™„ë£Œ)

# 2. API ì„œë²„ ì‹œì‘ 
APP_ENV=dev uv run python main.py serve-api --run-id latest

# 3. Feature Store ì—°ë™ í…ŒìŠ¤íŠ¸
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"user_id": "user_001", "age": 35}'

# 4. í™˜ê²½ë³„ ì‘ë‹µ ì •ì±… í™•ì¸
# DEV (Feature Store ì—°ê²°): HTTP 200 + ì˜ˆì¸¡ ê²°ê³¼
# LOCAL (Feature Store ë¯¸ì—°ê²°): HTTP 503 + ì—ëŸ¬ ë©”ì‹œì§€
```

#### **3. Feature Store ê°œë°œ**
```bash
# 1. ìƒˆ í”¼ì²˜ ë°ì´í„° ì¶”ê°€ (PostgreSQL)
docker-compose exec postgresql psql -U mluser -d mlpipeline
# > ìƒˆ í…Œì´ë¸” ìƒì„± ë° ë°ì´í„° ì‚½ì…

# 2. Feast FeatureView ì •ì˜ (feast/features.py)
# > ìƒˆ FeatureView ì¶”ê°€

# 3. Feature Store ì—…ë°ì´íŠ¸
cd feast
feast apply
feast materialize-incremental $(date -d '1 day ago' +%Y-%m-%d) $(date +%Y-%m-%d)

# 4. modern-ml-pipelineì—ì„œ í™œìš©
# > Recipe íŒŒì¼ì— ìƒˆ í”¼ì²˜ ì¶”ê°€
```

### **ë°°í¬ ì‹œë‚˜ë¦¬ì˜¤**

#### **Local Development** ğŸ 
- mmp-local-dev ì—†ì´ modern-ml-pipelineë§Œ ì‹¤í–‰
- MLflow: ë¡œì»¬ íŒŒì¼ ëª¨ë“œ
- Feature Store: íŒŒì¼ ê¸°ë°˜ ë˜ëŠ” ë¹„í™œì„±í™”
- API: 503 ì‘ë‹µ (Feature Store ë¯¸ì—°ê²°)

#### **Development** ğŸ§ª  
- mmp-local-dev + modern-ml-pipeline ì—°ë™
- MLflow: Docker ì„œë²„ (localhost:5002)
- Feature Store: PostgreSQL + Redis
- API: 200 ì‘ë‹µ (ì™„ì „ ê¸°ëŠ¥)

#### **Production** ğŸš€
- modern-ml-pipelineë§Œ ë°°í¬
- MLflow: ì™¸ë¶€ ì„œë²„ (https://mlflow.company.com)
- Feature Store: í”„ë¡œë•ì…˜ ì¸ìŠ¤í„´ìŠ¤
- API: 200 ì‘ë‹µ (í”„ë¡œë•ì…˜ ë°ì´í„°)

---

## ğŸ“š **ì°¸ê³  ìë£Œ**

### **ê´€ë ¨ ë¬¸ì„œ**
- [modern-ml-pipeline](../modern-ml-pipeline/README.md) - ë©”ì¸ ML íŒŒì´í”„ë¼ì¸
- [dev-contract.yml](./dev-contract.yml) - API ê³„ì•½ì„œ
- [Blueprint ì•„í‚¤í…ì²˜](../modern-ml-pipeline/.claude/BLUEPRINT.md) - ì„¤ê³„ ì² í•™
- [ê°œë°œ ê³„íš](../modern-ml-pipeline/.claude/DEV_PLANS.md) - ë¡œë“œë§µ

### **ê¸°ìˆ  ìŠ¤íƒ ë¬¸ì„œ**
- [Docker Compose](https://docs.docker.com/compose/) - ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- [PostgreSQL](https://www.postgresql.org/docs/) - ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤  
- [Redis](https://redis.io/documentation) - ì¸ë©”ëª¨ë¦¬ ë°ì´í„° ìŠ¤í† ì–´
- [MLflow](https://mlflow.org/docs/latest/index.html) - ML ì‹¤í—˜ ì¶”ì 
- [Feast](https://feast.dev/) - Feature Store

### **ê°œë°œ ë„êµ¬**
- [OrbStack](https://orbstack.dev/) - macOS Docker í™˜ê²½ (ì¶”ì²œ)
- [Docker Desktop](https://www.docker.com/products/docker-desktop/) - í¬ë¡œìŠ¤í”Œë«í¼ Docker
- [DBeaver](https://dbeaver.io/) - PostgreSQL GUI í´ë¼ì´ì–¸íŠ¸
- [Redis Insight](https://redis.io/insight/) - Redis GUI í´ë¼ì´ì–¸íŠ¸

---

## ğŸ·ï¸ **ë²„ì „ ì •ë³´**

- **Version**: 1.0.0
- **Python**: 3.11+
- **Docker**: 20.10+
- **modern-ml-pipeline**: Compatible with all versions

### **ë³€ê²½ ì´ë ¥**
- **v1.0.0** (2024-01-19)
  - ì´ˆê¸° ë¦´ë¦¬ìŠ¤
  - PostgreSQL + Redis + MLflow + Feast í†µí•©
  - modern-ml-pipeline ì™„ì „ í˜¸í™˜
  - ML í…ŒìŠ¤íŠ¸ ë°ì´í„° 1000+ ìƒ˜í”Œ ì œê³µ
  - ì‹œë‚˜ë¦¬ì˜¤ë³„ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì§€ì›

---

## ğŸ“„ **ë¼ì´ì„¼ìŠ¤**

MIT License - ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

---

## ğŸ™‹â€â™‚ï¸ **ì§€ì›**

ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´:

1. **í†µí•© í…ŒìŠ¤íŠ¸ ë¨¼ì € ì‹¤í–‰**: `python test-integration.py`
2. **ë¡œê·¸ í™•ì¸**: `docker-compose logs [service-name]` 
3. **ì´ìŠˆ ë¦¬í¬íŠ¸**: GitHub Issuesì— ìƒì„¸í•œ ì •ë³´ì™€ í•¨ê»˜ ë“±ë¡
4. **ê°œë°œíŒ€ ì—°ë½**: ë‚´ë¶€ Slack ì±„ë„ ë˜ëŠ” ì´ë©”ì¼

---

<div align="center">

**ğŸš€ Happy ML Development with mmp-local-dev! ğŸš€**

Made with â¤ï¸ for Modern ML Pipeline

</div>